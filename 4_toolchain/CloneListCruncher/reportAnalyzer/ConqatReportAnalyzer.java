package reportAnalyzer;
import java.io.BufferedOutputStream;
import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.io.ObjectOutput;
import java.io.ObjectOutputStream;
import java.io.OutputStream;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Locale;
import java.util.Map;

import javax.xml.parsers.DocumentBuilder;
import javax.xml.parsers.DocumentBuilderFactory;
import javax.xml.parsers.ParserConfigurationException;

import org.w3c.dom.Document;
import org.w3c.dom.Element;
import org.w3c.dom.Node;
import org.w3c.dom.NodeList;
import org.xml.sax.SAXException;

import data.Clone;
import data.CloneData;

/**
 * conqatReportAnalyzer - (Google) Code Jam Extractor
 * This is a small helper tool to analyze the cloning reports generated by conqat.
 * (c) 2014 Ivan Bogicevic
 * 
 * @author ivan
 */

public class ConqatReportAnalyzer {

	// maximum number of solutions
	final static int MAXSOLUTIONS = 14;

	// language of study objects
	final static String LANGUAGE = "Java";
	//final static String LANGUAGE = "C";

	// file ending of the source files
	final String SOURCEENDING = ".java";
	//final static String SOURCEENDING = ".c";

	// local path to the conqat results folder
	static String inputFolder = "/Users/ivan/Documents/Projekte/2014_ICSE15_Study/study-results/conqat/";

	// local path to the study objects
	static String sourceFolder = "/Users/ivan/Documents/Projekte/2014_ICSE15_Study/study-objects/GoogleCodeJam";

	// number of solutions per study object
	final int SAMPLESIZE = 100;

	// clone table: rows and columns are solutions (files);
	private int[][] tableP = new int[SAMPLESIZE+1][SAMPLESIZE+1]; // for partial clones
	private int[][] tableF = new int[SAMPLESIZE+1][SAMPLESIZE+1]; // for full clones

	// recall metrices
	private double recallP12 = 0;
	private double recallP123 = 0;
	private double recallP1234 = 0;
	private double recallF12 = 0;
	private double recallF123 = 0;
	private double recallF1234 = 0;

	// list of all clone data of all solution sets (only needed for exported serialization file)
	private static CloneData cloneData = new CloneData();

	// storage for source file lengths (only code without header comments)
	Map<Integer, Integer> fileLengths = new HashMap<Integer, Integer>();

	// prints a message to the standard output
	private void log(String msg) {
		System.out.println(msg);
	}

	// prints a single star to the standard output (to show progress)
	private void logStar() {
		System.out.print("*");
	}

	// analyzed a single clone pair and add its result to the table
	private void analyzeClonePair(Element cloneLeft, Element cloneRight, int solutionSetNumber) {

		int cloneLeftFileName = Integer.parseInt(cloneLeft.getAttribute("sourceFileId")) + 1;
		int cloneRightFileName = Integer.parseInt(cloneRight.getAttribute("sourceFileId")) + 1;

		// check if partial or full clone
		int cloneLeftStartLine = Integer.parseInt(cloneLeft.getAttribute("startLine"));
		int cloneLeftEndLine = Integer.parseInt(cloneLeft.getAttribute("endLine"));
		int cloneRightStartLine = Integer.parseInt(cloneRight.getAttribute("startLine"));
		int cloneRightEndLine = Integer.parseInt(cloneRight.getAttribute("endLine"));
		int cloneLeftLength = (cloneLeftEndLine - cloneLeftStartLine);
		int cloneRightLength = (cloneRightEndLine - cloneRightStartLine);
		// fill clone if both clone lenghts are long enough
		boolean isFull = (cloneLeftLength >= fileLengths.get(cloneLeftFileName) - 2)
				&& (cloneRightLength >= fileLengths.get(cloneRightFileName) - 2);
		log ("cloneLeftLength/fileLeftLength = " + cloneLeftLength + "/" + fileLengths.get(cloneLeftFileName));
		log ("cloneRightLength/fileRightLength = " + cloneRightLength + "/" + fileLengths.get(cloneRightFileName));

		// check clone type
		String cloneLeftGap = cloneLeft.getAttribute("gaps");
		String cloneRightGap = cloneRight.getAttribute("gaps");
		int type;
		if (cloneLeftGap.length() > 0 || cloneRightGap.length() > 0) {
			// there is a gap, so type 3 (4 cannot be detected by conqat)
			type = 3;
		} else {
			// there is no gap, so type 2 (or 1, but thats ignored here)
			type = 2;
		}		

		// add result to table
		if (cloneLeftFileName > cloneRightFileName) {
			// swap indices
			int temp = cloneRightFileName;
			cloneRightFileName = cloneLeftFileName;
			cloneLeftFileName = temp;
			// swap start lines
			temp = cloneRightStartLine;
			cloneRightStartLine = cloneLeftStartLine;
			cloneLeftStartLine = temp;
			// swap end lines
			temp = cloneRightEndLine;
			cloneRightEndLine = cloneLeftEndLine;
			cloneLeftEndLine = temp;
		}
		if (cloneLeftFileName == cloneRightFileName) {
			// ignore clone within same file
			return;
		}
		int oldResult;
		int newResult;
		if (isFull) {
			// full clone, so care only about tableF
			oldResult = tableF[cloneLeftFileName][cloneRightFileName];
		} else {
			// partial clone, so care only about tableP
			oldResult = tableP[cloneLeftFileName][cloneRightFileName];
		}
		// overwrite old value correctly by taking the smaller one (2&2->2; 2&3->2; 3&2->2; 3&3->3)
		if (oldResult == 0) {
			newResult = type;
		} else {
			newResult = Math.min(oldResult, type);
		}
		// write back to the correct table
		if (isFull) {
			// full clone
			tableF[cloneLeftFileName][cloneRightFileName] = newResult;
			log("added result tableF[" + cloneLeftFileName + "][" + cloneRightFileName + "]=\"" + newResult + "\"");
		} else {
			// partial clone
			tableP[cloneLeftFileName][cloneRightFileName] = newResult;
			log("added result tableP[" + cloneLeftFileName + "][" + cloneRightFileName + "]=\"" + newResult + "\"");
		}	

		// remember clone in global clone data list (later needed for serialization)
		String cloneCoverage;
		if (isFull) {
			cloneCoverage = "FULL";
		} else {
			cloneCoverage = "PART";
		}
		if (oldResult != newResult) {
			Clone clone = new Clone(LANGUAGE.toUpperCase(), solutionSetNumber, cloneLeftFileName,
					cloneLeftStartLine, cloneLeftEndLine, cloneRightFileName, cloneRightStartLine,
					cloneRightEndLine, cloneCoverage, newResult); 
			cloneData.cloneList.add(clone);
		}
	}

	// read a conqat report and analyze the results
	private void parseXml(int solutionSetNumber) {
		// the local path to the conqat result xml
		String inputPath = inputFolder + LANGUAGE +  File.separator + solutionSetNumber + File.separator + "clones-gapped.xml";

		// parse the xml file
		File xml = new File(inputPath);
		DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();
		DocumentBuilder db;
		try {
			// parse xml
			db = dbf.newDocumentBuilder();
			Document doc;
			doc = db.parse(xml);
			doc.getDocumentElement().normalize();

			// iterate through clone classes
			NodeList cloneClasses = doc.getElementsByTagName("cloneClass");
			for (int i = 0; i < cloneClasses.getLength(); i++) {
				Node cloneClass = cloneClasses.item(i);
				if (cloneClass.getNodeType() != Node.ELEMENT_NODE) {
					continue;
				}
				Element ccElement = (Element) cloneClass;
				log("\nanalyzing clone class id=" + ccElement.getAttribute("id"));

				// iterate through clones within the clone class
				NodeList clones = cloneClass.getChildNodes();
				List<Element> cElements = new ArrayList<Element>();
				// get clones of that class
				for (int i2 = 0; i2 < clones.getLength(); i2++) {
					Node clone = clones.item(i2);
					if (!(clone.getNodeType() == Node.ELEMENT_NODE && clone.getNodeName().equals("clone"))) {
						continue;
					}
					Element cElement = (Element) clone;
					cElements.add(cElement);
					log("analyzing clone id=" + cElement.getAttribute("id"));
				}

				// get clone pairs of that class
				for (int left = 0; left < cElements.size() - 1; left++){
					for (int right = left + 1; right < cElements.size(); right++){
						Element cloneLeft = cElements.get(left);
						Element cloneRight = cElements.get(right);
						log("analyzing clone pair id=" + cloneLeft.getAttribute("id") + " and " + cloneRight.getAttribute("id"));
						analyzeClonePair(cloneLeft, cloneRight, solutionSetNumber);
					}
				}

			}
		} catch (ParserConfigurationException | SAXException | IOException e) {
			e.printStackTrace();
		}
	}

	// save the results as csv
	private void exportCsv(int solutionSetNumber) throws IOException {

		log("\nstarting csv export");

		// file init
		File csvFileF = new File(inputFolder + LANGUAGE + File.separator + solutionSetNumber + File.separator + "clone-analysis-full.csv");
		File csvFileP = new File(inputFolder + LANGUAGE + File.separator + solutionSetNumber + File.separator + "clone-analysis-partial.csv");
		BufferedWriter csvF = new BufferedWriter(new FileWriter(csvFileF));
		BufferedWriter csvP = new BufferedWriter(new FileWriter(csvFileP));

		// write column label (right file)
		csvF.write(",");
		csvP.write(",");
		for (int column = 1; column <= SAMPLESIZE; column++) {
			csvF.write(Integer.toString(column));
			csvP.write(Integer.toString(column));
			if (column < SAMPLESIZE) {
				csvF.write(",");
				csvP.write(",");
			}
		}
		csvF.write("\n");
		csvP.write("\n");

		// fill csv line by line
		for (int line = 1; line <= SAMPLESIZE; line++) {
			// write line label (left file)
			csvF.write(line + ",");
			csvP.write(line + ",");
			// fill line			
			for (int column = 1; column <= SAMPLESIZE; column++) {
				int f = tableF[line][column];
				if (f != 0) {
					csvF.write("" + f);
				}
				int p = tableP[line][column];
				if (p != 0) {
					csvP.write("" + p);
				}

				if (column < SAMPLESIZE) {
					csvF.write(",");
					csvP.write(",");
				}
			}
			csvF.write("\n");
			csvP.write("\n");
		}

		// export recall metrices
		csvP.write("Recall T1/2: " + String.format("%f", recallP12) + "\n");
		csvP.write("Recall T1/2/3: " + String.format("%f", recallP123) + "\n");
		csvF.write("Recall T1/2: " + String.format("%f", recallF12) + "\n");
		csvF.write("Recall T1/2/3: " + String.format("%f", recallF123) + "\n");
		log("exported recall values p12=" + recallP12 + " p123=" + recallP123 + " f12=" + recallF12 + " f123=" + recallF123);

		// close writer
		csvF.close();
		csvP.close();

		log("exported to " + csvFileF.getAbsolutePath());
		log("exported to " + csvFileP.getAbsolutePath() + "\n");
	}

	// calculates the number of source code lines of a file (without header comments)
	private int calcFileLength(String filePath){
		int lines = 0;
		boolean skip = false;
		String read;
		File file2Count = new File(filePath);
		try {
			BufferedReader reader = new BufferedReader(new FileReader(file2Count));
			while ((read = reader.readLine()) != null) {
				if(skip){
					read.endsWith("*/");
					skip = false;
				}
				if( read.startsWith("/*")){
					skip = true;
				}
				if (!(lines == 0 && read.startsWith("//")))
					lines++;
			}
			reader.close();
		} catch (IOException e) {
			e.printStackTrace();
		}

		return lines;
	}

	// calculates the file length of all source files
	private void calcFileLengths(int solutionSetNumber) {
		for (int solutionNo = 1; solutionNo <= SAMPLESIZE; solutionNo++) {
			String path = sourceFolder + LANGUAGE + File.separator + solutionSetNumber
					+ File.separator + "src" + File.separator
					+ String.format("%03d", solutionNo) + SOURCEENDING;
			fileLengths.put(solutionNo, calcFileLength(path));
		}
	}

	// calculates the recall metrices
	private void calcRecall() {
		int p12 = 0;
		int p123 = 0;
		int p1234 = 0;
		int f12 = 0;
		int f123 = 0;
		int f1234 = 0;
		for (int i = 1; i <= SAMPLESIZE; i++) {
			for (int j = 1; j <= SAMPLESIZE; j++) {
				int f = tableF[i][j];
				if (f == 1 || f == 2) {
					f12++;
					f123++;
					f1234++;
				} else if (f == 3) {
					f123++;
					f1234++;
				} else if (f == 4) {
					f1234++;
				}
				int p = tableP[i][j];
				if (p == 1 || p == 2) {
					p12++;
					p123++;
					p1234++;
				} else if (p == 3) {
					p123++;
					p1234++;
				} else if (p == 4) {
					p1234++;
				}
			}
		}
		recallP12   = (double)p12   / (double)(SAMPLESIZE * (SAMPLESIZE-1) / 2);
		recallP123  = (double)p123  / (double)(SAMPLESIZE * (SAMPLESIZE-1) / 2);
		recallP1234 = (double)p1234 / (double)(SAMPLESIZE * (SAMPLESIZE-1) / 2);
		recallF12  = (double)f12  / (double)(SAMPLESIZE * (SAMPLESIZE-1) / 2);
		recallF123 = (double)f123 / (double)(SAMPLESIZE * (SAMPLESIZE-1) / 2);
		recallF1234 = (double)f1234 / (double)(SAMPLESIZE * (SAMPLESIZE-1) / 2);
	}

	// read a conqat report, analyze the results and save the results as csv
	private void transformReport(int solutionSetNumber) {

		// calculate file lengths and header comment lengths in lines of code
		calcFileLengths(solutionSetNumber);

		// read a conqat report, analyze the results
		parseXml(solutionSetNumber);

		// calculate recall
		calcRecall();

		// save the results as csv
		try {
			exportCsv(solutionSetNumber);
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	// constructor
	public ConqatReportAnalyzer() {
		// init table
		for (int i = 0; i < SAMPLESIZE+1; i++) {
			for (int j = 0; j < SAMPLESIZE+1; j++) {
				tableF[i][j] = 0;
				tableP[i][j] = 0;
			}
		}
	}

	// writes all clone data to a serialized file (the CCCD-Analyzer needs that data);
	public static void serializeCloneData() {
		// open stream
		OutputStream file;
		try {
			file = new FileOutputStream(inputFolder + File.separator + "conqatData" + LANGUAGE.toUpperCase() + ".ser");
			OutputStream buffer = new BufferedOutputStream(file);
			ObjectOutput output = new ObjectOutputStream(buffer);
			output.writeObject(cloneData);
			output.close();
		} catch (IOException e) {
			e.printStackTrace();
		}
	}

	public static void main(String[] args) {

		// create csv-file for recall metrices
		File csvRecallFile = new File(inputFolder + LANGUAGE + File.separator + "clone-analysis-summary.csv");
		BufferedWriter csvRecall = null;
		try {
			csvRecall = new BufferedWriter(new FileWriter(csvRecallFile));
		} catch (IOException e) {
			e.printStackTrace();
		}

		// iterate through all folder of one language
		for (int solutionSetNumber = 1; solutionSetNumber <= MAXSOLUTIONS; solutionSetNumber++) {

			// initialize
			ConqatReportAnalyzer cra = new ConqatReportAnalyzer();

			// read a conqat report, analyze the results and save the results as csv
			cra.transformReport(solutionSetNumber);

			// write the recall values to the recall cvs file; SO = solution
			try {
				csvRecall.write("conqat;" + LANGUAGE.toLowerCase() + ";" + solutionSetNumber + ";p12; "+ String.format(Locale.ENGLISH, "%f", cra.recallP12) + "\n");
				csvRecall.write("conqat;" + LANGUAGE.toLowerCase() + ";" + solutionSetNumber + ";p123; "+ String.format(Locale.ENGLISH, "%f", cra.recallP123) + "\n");
				csvRecall.write("conqat;" + LANGUAGE.toLowerCase() + ";" + solutionSetNumber + ";p1234; "+ String.format(Locale.ENGLISH, "%f", cra.recallP1234) + "\n");
				csvRecall.write("conqat;" + LANGUAGE.toLowerCase() + ";" + solutionSetNumber + ";f12; "+ String.format(Locale.ENGLISH, "%f", cra.recallF12) + "\n");
				csvRecall.write("conqat;" + LANGUAGE.toLowerCase() + ";" + solutionSetNumber + ";f123; "+ String.format(Locale.ENGLISH, "%f", cra.recallF123) + "\n");
				csvRecall.write("conqat;" + LANGUAGE.toLowerCase() + ";" + solutionSetNumber + ";f1234; "+ String.format(Locale.ENGLISH, "%f", cra.recallF1234) + "\n");
			} catch (IOException e) {
				e.printStackTrace();
			}

			// finalize
			cra.log("--- conqatReportAnalyzer ended ---\n");
		}

		try {
			csvRecall.close();
		} catch (IOException e) {
			e.printStackTrace();
		}

		// writes all clone data to a serialized file (the CCCD-Analyzer needs that data);
		serializeCloneData();
	}

}